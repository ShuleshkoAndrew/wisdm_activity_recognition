defaults:
  - _self_
  - training/default
  - model/default
  - preprocessing/default
  - paths/default
  - mlflow/default
  - inference/default
  - plotting/default

# Global settings
seed: 42
debug: false

# Shared parameters used by both preprocessing and model
window_size: 100  # 5 seconds at 20Hz
window_overlap: 0.5  # 50% overlap
sampling_rate: 20  # Hz
random_seed: 42

model:
  # Model architecture
  n_channels: 3  # x, y, z acceleration
  n_classes: 6  # Number of activities
  window_size: ${window_size}
  window_overlap: ${window_overlap}
  sampling_rate: ${sampling_rate}
  hidden_size: 64  # LSTM hidden state size
  n_lstm_layers: 2  # Number of LSTM layers
  dropout: 0.5  # Dropout probability

training:
  # Trainer configuration
  trainer:
    max_epochs: 10
    accelerator: "auto"
    devices: "auto"
    deterministic: true
    gradient_clip_val: 1.0
    accumulate_grad_batches: 1
    precision: 32
    enable_progress_bar: true
    enable_model_summary: true
    enable_checkpointing: true
    log_every_n_steps: 10

  # Data parameters
  batch_size: 32
  num_workers: 4
  seed: ${random_seed}

  # Optimizer settings
  optimizer:
    name: "Adam"
    lr: 0.001
    weight_decay: 0.0001

  # Learning rate scheduler
  lr_scheduler:
    name: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.1
    patience: 5
    min_lr: 1.0e-6
    monitor: "val_loss"

  # Callbacks configuration
  callbacks:
    model_checkpoint:
      dirpath: ${paths.models_dir}/checkpoints
      filename: "model-{epoch:02d}-{val_loss:.2f}"
      monitor: "val_loss"
      mode: "min"
      save_top_k: 3
      save_last: true

    early_stopping:
      monitor: "val_loss"
      mode: "min"
      patience: 10
      min_delta: 0.001

    lr_monitor:
      logging_interval: "epoch"

preprocessing:
  # Split sizes (must sum to 1.0)
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15

  # Preprocessing options
  normalize: true
  standardize: true
  remove_outliers: true
  outlier_threshold: 3.0

paths:
  data_dir: ${oc.env:PROJECT_ROOT}/data
  raw_data: ${paths.data_dir}/raw
  processed_data: ${paths.data_dir}/processed
  models_dir: ${oc.env:PROJECT_ROOT}/models
  onnx_dir: ${paths.models_dir}/onnx
  plots_dir: ${oc.env:PROJECT_ROOT}/plots

mlflow:
  tracking_uri: ${oc.env:MLFLOW_TRACKING_URI,file://${oc.env:PROJECT_ROOT}/mlruns}
  experiment_name: wisdm_activity_recognition
  model_name: cnn_lstm_v1

hydra:
  job:
    chdir: false  # Don't change working directory
